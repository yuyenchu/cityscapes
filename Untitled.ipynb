{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49c0e340-c403-4cc9-ac61-be459498f6ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from clearml import Task\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b17a3e05-3541-466e-8536-0210fa4a5d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SE_block(inputs, reduction_factor=2):\n",
    "    input_channels = int(inputs.shape[-1])\n",
    "    x = layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = layers.Dense(input_channels//reduction_factor, activation='relu')(x)\n",
    "    x = layers.Dense(input_channels, activation='hard_sigmoid')(x)\n",
    "    x = layers.Reshape((1, 1, input_channels))(x)\n",
    "    x = layers.Multiply()([inputs, x])\n",
    "    return x\n",
    "\n",
    "class SE_Block(tf.keras.layers.Layer):\n",
    "    def __init__(self, reduction_factor=4, name=None):\n",
    "        super(SE_Block, self).__init__(name=name)\n",
    "        self.reduction_factor = reduction_factor\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'reduction_factor': self.reduction_factor\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_channels = int(input_shape[-1])\n",
    "        self.pool = layers.GlobalAveragePooling2D()\n",
    "        self.d1 = layers.Dense(input_channels//self.reduction_factor, activation='relu6')\n",
    "        self.d2 = layers.Dense(input_channels, activation='hard_sigmoid')\n",
    "        self.reshape = layers.Reshape((1, 1, input_channels))\n",
    "        self.out = layers.Multiply()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.pool(inputs)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.reshape(x)\n",
    "        return self.out([inputs, x])\n",
    "\n",
    "class Conv_Block(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel, filters, stride, activation=tf.nn.relu6, name=None):\n",
    "        super(Conv_Block, self).__init__(name=name)\n",
    "        self.kernel = kernel\n",
    "        self.filters = filters\n",
    "        self.activation = activation\n",
    "        self.stride = stride\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kernel': self.kernel,\n",
    "            'filters': self.filters,\n",
    "            'stride': self.stride,\n",
    "            'activation': self.activation\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.p_conv = layers.Conv2D(self.filters, 1, padding='same', activation=self.activation)\n",
    "        self.d_conv = layers.DepthwiseConv2D(self.kernel, self.stride, 'same', activation=self.activation)\n",
    "        # self.conv = layers.SeparableConv2D(self.filters,self.kernel,self.stride,'same',activation=self.activation)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.p_conv(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.d_conv(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "        # return self.conv(inputs)\n",
    "\n",
    "def hswish(x):\n",
    "    return x * tf.nn.relu6(x + 3) / 6\n",
    "\n",
    "class MNV3_Block(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel, filters, stride=1, activation=tf.nn.relu6, reduction_factor=4, name=None):\n",
    "        super(MNV3_Block, self).__init__(name=name)\n",
    "        self.kernel = kernel\n",
    "        self.filters = filters\n",
    "        self.stride = stride\n",
    "        self.activation = activation\n",
    "        self.reduction_factor = reduction_factor\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kernel': self.kernel,\n",
    "            'filters': self.filters,\n",
    "            'stride': self.stride,\n",
    "            'activation': self.activation,\n",
    "            'reduction_factor': self.reduction_factor\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv = Conv_Block(self.kernel, self.filters, self.stride, self.activation)\n",
    "        self.se = SE_Block(self.reduction_factor)\n",
    "        self.out = layers.Conv2D(self.filters, 1, padding='same', activation=self.activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.se(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "def get_enhanced_efm(CLASS_NUIM = 3):\n",
    "    # down sample\n",
    "    input = tf.keras.Input((416,416,3),name='input')\n",
    "    x1 = MNV3_Block(3,16,2,hswish,name='block1')(input)\n",
    "    x2 = MNV3_Block(5,40,2,name='block2')(x1)\n",
    "    x2, x2p = tf.split(x2,num_or_size_splits=2, axis=-1)\n",
    "    x3 = MNV3_Block(3,80,2,hswish,name='block3')(x2)\n",
    "    x3, x3p = tf.split(x3,num_or_size_splits=2, axis=-1)\n",
    "    x4 = MNV3_Block(3,160,2,hswish,name='block4')(x3)\n",
    "    x4, x4p = tf.split(x4,num_or_size_splits=2, axis=-1)\n",
    "    x5 = MNV3_Block(3,320,2,hswish,name='block5')(x4)\n",
    "    # up sample\n",
    "    p5 = layers.Conv2DTranspose(160,3,2,padding='same',name='up5')(x5)\n",
    "    x4 = layers.Concatenate()([x4,x4p])\n",
    "    p5 = layers.Add(name='fuse1')([p5, layers.Conv2D(160, 1, padding='same', activation='relu6')(x4)])\n",
    "\n",
    "    p4 = layers.Conv2DTranspose(80,3,2,padding='same',name='up4')(p5)\n",
    "    x3 = layers.Concatenate()([x3,x3p])\n",
    "    p4 = layers.Add(name='fuse2')([p4, layers.Conv2D(80, 1, padding='same', activation='relu6')(x3)])\n",
    "\n",
    "    p3 = layers.Conv2DTranspose(40,3,2,padding='same',name='up3')(p4)\n",
    "    x2 = layers.Concatenate()([x2,x2p])\n",
    "    p3 = layers.Add(name='fuse3')([p3, layers.Conv2D(40, 1, padding='same', activation='relu6')(x2)])\n",
    "\n",
    "    p2 = layers.Conv2DTranspose(16,3,2,padding='same',name='up2')(p3)\n",
    "    # p2 = layers.Add(name='fuse4')([p2, layers.Conv2D(16, 1, padding='same', activation='relu6')(x1)])\n",
    "    # bottom-up augmentation\n",
    "    n2 = layers.SeparableConv2D(40,3,2,padding='same',name='bottomup1')(p2)\n",
    "    n2 = layers.Add(name='fuse5')([n2, p3])\n",
    "\n",
    "    n3 = layers.SeparableConv2D(80,3,2,padding='same',name='bottomup2')(n2)\n",
    "    n3 = layers.Add(name='fuse6')([n3, p4])\n",
    "\n",
    "    n4 = layers.SeparableConv2D(160,3,2,padding='same',name='bottomup3')(n3)\n",
    "    n4 = layers.Add(name='fuse7')([n4, p5])\n",
    "\n",
    "    n5 = layers.SeparableConv2D(320,3,2,padding='same',name='bottomup4')(n4)\n",
    "\n",
    "    n5 = layers.UpSampling2D(8)(n5)\n",
    "    n4 = layers.UpSampling2D(4)(n4)\n",
    "    n3 = layers.UpSampling2D(2)(n3)\n",
    "\n",
    "    out = layers.Concatenate()([n2,n3,n4,n5])\n",
    "    out = layers.Conv2DTranspose(16,3,2,padding='same',name='out1')(out)\n",
    "    out = layers.Conv2DTranspose(CLASS_NUIM,3,2,padding='same',name='out2')(out)\n",
    "    out = tf.keras.layers.Softmax(name='softmax_out')(out)\n",
    "\n",
    "    return Model(inputs=[input], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdb00311-b4d7-404d-b00d-c3d7377d1c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask\n",
    "\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint['image'], (416, 416))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (416, 416))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "class Augment(tf.keras.layers.Layer):\n",
    "    def __init__(self, seed=42):\n",
    "        super().__init__()\n",
    "        # both use the same seed, so they'll make the same random changes.\n",
    "        self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
    "        self.augment_labels = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
    "\n",
    "    def call(self, inputs, labels):\n",
    "        inputs = self.augment_inputs(inputs)\n",
    "        labels = self.augment_labels(labels)\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441ed41-950b-4590-92d2-8135e2d5e95b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 23:24:45.703347: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-02-12 23:24:45.703368: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 23:24:45.846525: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-02-12 23:24:45.879953: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - ETA: 0s - loss: 0.8210 - accuracy: 0.6299\n",
      "Epoch 1: val_loss improved from inf to 1.00706, saving model to emf_enhanced20230212-232445_ckpt\n",
      "102/102 [==============================] - 47s 392ms/step - loss: 0.8210 - accuracy: 0.6299 - val_loss: 1.0071 - val_accuracy: 0.5674\n",
      "Epoch 2/15\n",
      "  8/102 [=>............................] - ETA: 33s - loss: 0.7726 - accuracy: 0.6628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97/102 [===========================>..] - ETA: 1s - loss: 0.7608 - accuracy: 0.6689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 23:26:07.518911: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-02-12 23:26:07.518930: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.6687\n",
      "Epoch 2: val_loss improved from 1.00706 to 0.99711, saving model to emf_enhanced20230212-232445_ckpt\n",
      "102/102 [==============================] - 40s 394ms/step - loss: 0.7615 - accuracy: 0.6687 - val_loss: 0.9971 - val_accuracy: 0.5690\n",
      "Epoch 3/15\n",
      "  9/102 [=>............................] - ETA: 30s - loss: 0.7602 - accuracy: 0.6723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/102 [===>..........................] - ETA: 29s - loss: 0.7619 - accuracy: 0.6723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 23:26:18.433284: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2023-02-12 23:26:18.473142: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2023-02-12 23:26:18.687596: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 31548 callback api events and 30983 activity events. \n",
      "2023-02-12 23:26:18.814195: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-02-12 23:26:18.819842: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: emf_enhanced20230212-232445/plugins/profile/2023_02_12_23_26_18/Ubuntu-CNL-1.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - ETA: 0s - loss: 0.7494 - accuracy: 0.6788\n",
      "Epoch 3: val_loss did not improve from 0.99711\n",
      "102/102 [==============================] - 40s 394ms/step - loss: 0.7494 - accuracy: 0.6788 - val_loss: 1.0085 - val_accuracy: 0.4004\n",
      "Epoch 4/15\n",
      "  9/102 [=>............................] - ETA: 30s - loss: 0.7479 - accuracy: 0.6798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/102 [=>............................] - ETA: 30s - loss: 0.7455 - accuracy: 0.6800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.6845\n",
      "Epoch 4: val_loss did not improve from 0.99711\n",
      "102/102 [==============================] - 39s 386ms/step - loss: 0.7381 - accuracy: 0.6845 - val_loss: 1.0237 - val_accuracy: 0.3468\n",
      "Epoch 5/15\n",
      " 10/102 [=>............................] - ETA: 29s - loss: 0.7370 - accuracy: 0.6869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/102 [==>...........................] - ETA: 29s - loss: 0.7346 - accuracy: 0.6871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - ETA: 0s - loss: 0.7299 - accuracy: 0.6893"
     ]
    }
   ],
   "source": [
    "task = Task.init(project_name='semantic_segmentation', task_name='efm on pets')\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 36\n",
    "VAL_SUBSPLITS = 5\n",
    "BUFFER_SIZE = 64\n",
    "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "train_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "model = get_enhanced_efm()\n",
    "train_batches = (\n",
    "    train_images\n",
    "    .shuffle(BUFFER_SIZE, seed=0)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    "    .map(Augment())\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "test_batches = test_images.batch(BATCH_SIZE)\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "logs = f'emf_enhanced{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "checkpoint_path = f'emf_enhanced{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}_ckpt'\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                histogram_freq = 1,\n",
    "                                                profile_batch = '200,220')\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit(train_batches, epochs=EPOCHS,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        validation_steps=VALIDATION_STEPS,\n",
    "                        validation_data=test_batches,\n",
    "                        callbacks=[tboard_callback,cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe92cca-6ed4-4f94-9fd5-413f1fdd2193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task.upload_artifact('enhanced_efm', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14090ac1-9bae-4aba-9bc6-ecf50e9c5167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_batches)\n",
    "model.save('enhanced_efm')\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab3973-8411-4ca7-ac44-36c5a17f2f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
